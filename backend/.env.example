# ====================
# 后端环境变量示例
# ====================
# 说明：
# - 请复制为 backend/.env 并按需修改
# - 不要提交真实的密钥/Token 到仓库

# ====================
# 基础配置
# ====================
# 运行环境：development / test / production
NODE_ENV=development

# 后端监听端口（backend/src/main.ts 会读取 PORT）
PORT=5181

# API 路由前缀（例如 /api）
API_PREFIX=api

# CORS 允许来源，开发阶段可使用 *，生产建议填写前端域名
CORS_ORIGIN=*

# ====================
# PostgreSQL（Prisma）
# ====================
# Prisma 默认读取 DATABASE_URL
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/meeting_ai

# 兼容字段：ConfigurationService / configuration.ts 读取 postgres.url
POSTGRES_URL=postgresql://postgres:postgres@localhost:5432/meeting_ai

# ====================
# MongoDB（Mongoose）
# ====================
# 运行时实际连接字段：backend/src/database/mongodb.module.ts 读取 MONGODB_URI
MONGODB_URI=mongodb://localhost:27017/meeting_ai

# 兼容字段：ConfigurationService / configuration.ts 读取 mongo.url
MONGODB_URL=mongodb://localhost:27017/meeting_ai

# ====================
# AI 模型配置
# ====================
# GLM（智谱）Chat Completions（语句拆分模块读取 GLM_API_KEY）
GLM_API_KEY=your_glm_api_key

# 可选：自定义 GLM Endpoint（ConfigurationService 会读取 ai.glm.endpoint）
GLM_ENDPOINT=https://open.bigmodel.cn/api/paas/v4/chat/completions

# GLM 全局限流/队列（所有 GLM 请求共享）
# 并发上限（建议 1）
GLM_GLOBAL_CONCURRENCY=1
# 说明：不同模型/套餐并发配额不同（例如 GLM-4-Flash-250414 通用模型并发上限为 20），
# 若同时启用 ASR + 分段等功能，请综合评估后再调高全局并发。
# 启动请求最小间隔（毫秒），用于控制 QPS
GLM_GLOBAL_MIN_INTERVAL_MS=500
# 429 触发后的全局冷却（毫秒）
GLM_GLOBAL_RATE_LIMIT_COOLDOWN_MS=2000
# 429 冷却最大值（毫秒）
GLM_GLOBAL_RATE_LIMIT_MAX_MS=15000

# GLM 多路限流（按模块拆分；未配置时回退全局参数）
# ASR
GLM_ASR_CONCURRENCY=1
GLM_ASR_MIN_INTERVAL_MS=500
GLM_ASR_RATE_LIMIT_COOLDOWN_MS=2000
GLM_ASR_RATE_LIMIT_MAX_MS=15000
# 语句拆分
GLM_TRANSCRIPT_EVENT_SEGMENT_CONCURRENCY=1
GLM_TRANSCRIPT_EVENT_SEGMENT_MIN_INTERVAL_MS=500
GLM_TRANSCRIPT_EVENT_SEGMENT_RATE_LIMIT_COOLDOWN_MS=2000
GLM_TRANSCRIPT_EVENT_SEGMENT_RATE_LIMIT_MAX_MS=15000
# 语句翻译
GLM_TRANSCRIPT_EVENT_SEGMENT_TRANSLATION_CONCURRENCY=1
GLM_TRANSCRIPT_EVENT_SEGMENT_TRANSLATION_MIN_INTERVAL_MS=500
GLM_TRANSCRIPT_EVENT_SEGMENT_TRANSLATION_RATE_LIMIT_COOLDOWN_MS=2000
GLM_TRANSCRIPT_EVENT_SEGMENT_TRANSLATION_RATE_LIMIT_MAX_MS=15000
# AI 分析
GLM_TRANSCRIPT_ANALYSIS_CONCURRENCY=1
GLM_TRANSCRIPT_ANALYSIS_MIN_INTERVAL_MS=500
GLM_TRANSCRIPT_ANALYSIS_RATE_LIMIT_COOLDOWN_MS=2000
GLM_TRANSCRIPT_ANALYSIS_RATE_LIMIT_MAX_MS=15000

# ====================
# 实时转写（ASR）
# ====================
# GLM-ASR-2512：HTTP + SSE 流式返回，需要累积音频后发送

# 转写管线开关：legacy（默认）/ raw_llm（并行写入原文事件流，后续用于 LLM 分段）
TRANSCRIPT_PIPELINE=legacy

# ====================
# 语句拆分（transcript_events_segments）
# ====================
# 去抖间隔（毫秒）；0 表示每次事件更新都立即触发（不建议）
TRANSCRIPT_EVENTS_SEGMENT_INTERVAL_MS=3000

# 上下文窗口（CHUNK_SIZE）：取尾部 N 条事件作为 LLM 上下文
TRANSCRIPT_EVENTS_SEGMENT_CHUNK_SIZE=120
# 兼容别名（历史字段）：WINDOW_EVENTS 也作为窗口大小配置
# TRANSCRIPT_EVENTS_SEGMENT_WINDOW_EVENTS=120

# 收到 stop_transcribe 时立即触发一次语句拆分
TRANSCRIPT_EVENTS_SEGMENT_TRIGGER_ON_STOP_TRANSCRIBE=1

# 单次语句拆分最大生成段数
TRANSCRIPT_EVENTS_SEGMENT_MAX_SEGMENTS_PER_RUN=8

# 语句拆分使用的 GLM 模型（默认 glm-4xxx）
GLM_TRANSCRIPT_EVENT_SEGMENT_MODEL=glm-4XX

# 语句拆分：GLM 输出上限（tokens）
GLM_TRANSCRIPT_EVENT_SEGMENT_MAX_TOKENS=2000

# 语句拆分：GLM 输出上限补偿（tokens）
GLM_TRANSCRIPT_EVENT_SEGMENT_BUMP_MAX_TOKENS=4096

# 语句拆分：JSON 模式（1/true 启用，0/false 关闭）
GLM_TRANSCRIPT_EVENT_SEGMENT_JSON_MODE=1

# 语句拆分：GLM 429 限流重试配置
# 最大重试次数（0 表示不重试）
GLM_TRANSCRIPT_EVENT_SEGMENT_RETRY_MAX=5
# 退避基准延迟（毫秒）
GLM_TRANSCRIPT_EVENT_SEGMENT_RETRY_BASE_MS=500
# 退避最大延迟（毫秒）
GLM_TRANSCRIPT_EVENT_SEGMENT_RETRY_MAX_MS=8000

# ====================
# 全文分析总结（transcript-analysis）
# ====================
# 可选：单独指定“会议总结”模型；不配置时会回退使用 GLM_TRANSCRIPT_EVENT_SEGMENT_MODEL
GLM_TRANSCRIPT_SUMMARY_MODEL=glm-4XX

# 会议总结：输出上限（tokens）
GLM_TRANSCRIPT_SUMMARY_MAX_TOKENS=2500

# 会议总结：深度思考开关（1/true 启用，0/false 关闭）
GLM_TRANSCRIPT_SUMMARY_THINKING=1

# 针对性分析：深度思考开关（1/true 启用，0/false 关闭，未配置时沿用会议总结）
GLM_TRANSCRIPT_SEGMENT_ANALYSIS_THINKING=1

# 会议总结：GLM 429 限流重试配置（可选）
GLM_TRANSCRIPT_SUMMARY_RETRY_MAX=3
GLM_TRANSCRIPT_SUMMARY_RETRY_BASE_MS=500
GLM_TRANSCRIPT_SUMMARY_RETRY_MAX_MS=8000

# 转写自动切分间隔（毫秒）
TRANSCRIPT_AUTO_SPLIT_GAP_MS=2500

# 转写调试：打印语句日志（1/true 启用，0/false 关闭）
TRANSCRIPT_DEBUG_LOG_UTTERANCES=0

# 日志记录：请求与回复（1/true 启用，0/false 关闭）
APP_LOG_REQUEST_RESPONSE_ENABLED=0
# 日志记录：错误日志（1/true 启用，0/false 关闭）
APP_LOG_ERROR_ENABLED=0
# 日志记录：系统日志（1/true 启用，0/false 关闭）
APP_LOG_SYSTEM_ENABLED=0

# 语句翻译：是否在语句拆分后生成翻译（保留技术名/标识符）
# 说明：仅影响“翻译事件”，不会改变语句拆分的原文 content（用于对齐与后续拆分）。
TRANSCRIPT_SEGMENT_TRANSLATION_ENABLED=0
# 语句翻译：目标语言（如 简体中文 / English / 日本語）
TRANSCRIPT_SEGMENT_TRANSLATION_LANGUAGE=简体中文

# AI 分析：是否强制输出指定语言（1/true 启用，0/false 关闭）
TRANSCRIPT_ANALYSIS_LANGUAGE_ENABLED=1
# AI 分析：输出目标语言（如 简体中文 / English / 日本語）
TRANSCRIPT_ANALYSIS_LANGUAGE=简体中文

# AI 分析：会议总结系统提示词（可选，不配置则使用默认提示词）
# TRANSCRIPT_ANALYSIS_SUMMARY_SYSTEM_PROMPT=你是一名资深会议纪要/分析助手。
# AI 分析：分片总结系统提示词（可选，不配置则使用默认提示词）
# TRANSCRIPT_ANALYSIS_CHUNK_SUMMARY_SYSTEM_PROMPT=你是一名会议纪要助手。
# AI 分析：针对性分析系统提示词（可选，不配置则使用默认提示词）
# TRANSCRIPT_ANALYSIS_SEGMENT_SYSTEM_PROMPT=你是一名资深会议分析助手。
TRANSCRIPT_ANALYSIS_SUMMARY_SYSTEM_PROMPT=
TRANSCRIPT_ANALYSIS_CHUNK_SUMMARY_SYSTEM_PROMPT=
TRANSCRIPT_ANALYSIS_SEGMENT_SYSTEM_PROMPT=

# ASR 缓冲切分上限（毫秒）
# 软上限：有明显静音时优先在此切分
TRANSCRIPT_MAX_BUFFER_DURATION_SOFT_MS=30000
# 硬上限：无静音也强制切分，避免超过 ASR 限制
TRANSCRIPT_MAX_BUFFER_DURATION_HARD_MS=50000
