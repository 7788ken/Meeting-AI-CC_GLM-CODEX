# ====================
# 后端环境变量示例
# ====================
# 说明：
# - 请复制为 backend/.env 并按需修改
# - 不要提交真实的密钥/Token 到仓库

# ====================
# 基础配置
# ====================
# 运行环境：development / test / production
NODE_ENV=development

# 后端监听端口（backend/src/main.ts 会读取 PORT）
PORT=5181

# API 路由前缀（例如 /api）
API_PREFIX=api

# CORS 允许来源，开发阶段可使用 *，生产建议填写前端域名
CORS_ORIGIN=*

# ====================
# PostgreSQL（Prisma）
# ====================
# Prisma 默认读取 DATABASE_URL
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/meeting_ai

# 兼容字段：ConfigurationService / configuration.ts 读取 postgres.url
POSTGRES_URL=postgresql://postgres:postgres@localhost:5432/meeting_ai

# ====================
# MongoDB（Mongoose）
# ====================
# 运行时实际连接字段：backend/src/database/mongodb.module.ts 读取 MONGODB_URI
MONGODB_URI=mongodb://localhost:27017/meeting_ai

# 兼容字段：ConfigurationService / configuration.ts 读取 mongo.url
MONGODB_URL=mongodb://localhost:27017/meeting_ai

# ====================
# AI 模型配置
# ====================
# GLM（智谱）Chat Completions（backend/src/modules/analysis/clients/glm.client.ts 读取 GLM_API_KEY）
GLM_API_KEY=your_glm_api_key

# 可选：自定义 GLM Endpoint（ConfigurationService 会读取 ai.glm.endpoint）
GLM_ENDPOINT=https://open.bigmodel.cn/api/paas/v4/chat/completions

# 通义千问（如启用对应客户端/适配）
QIANWEN_API_KEY=your_qianwen_api_key
QIANWEN_ENDPOINT=https://dashscope.aliyuncs.com/api/v1

# 豆包大模型（如启用对应客户端/适配）
DOUBAO_API_KEY=your_doubao_api_key
DOUBAO_ENDPOINT=

# ====================
# 实时转写（WebSocket / ASR）
# ====================
# 转写管线开关：legacy（默认）/ raw_llm（并行写入原文事件流，后续用于 LLM 分段）
TRANSCRIPT_PIPELINE=legacy

# ====================
# 轮次分段（raw_llm）
# ====================
# 分段去抖间隔（毫秒）；0 表示每次事件更新都立即触发（不建议）
TRANSCRIPT_SEGMENT_INTERVAL_MS=3000

# 分段窗口：每次只对尾部 N 条事件做结构化分段并与历史结果合并
TRANSCRIPT_SEGMENT_WINDOW_EVENTS=120
# 轮次分段：GLM 输出上限（tokens）
GLM_TURN_SEGMENT_MAX_TOKENS=2000
# 轮次分段：JSON 模式（1/true 启用，0/false 关闭）
GLM_TURN_SEGMENT_JSON_MODE=1

# 分段模型：glm / heuristic（GLM 不可用时会自动回退 heuristic）
TRANSCRIPT_SEGMENT_MODEL=glm

# 收到 end_turn 时立即触发一次分段
TRANSCRIPT_SEGMENT_TRIGGER_ON_END_TURN=1

# 收到 stop_transcribe 时立即触发一次分段
TRANSCRIPT_SEGMENT_TRIGGER_ON_STOP_TRANSCRIBE=1

# ====================
# 转写语义分析（按事件流顺序分块）
# ====================
# 分块大小：每次处理 N 条转写事件
TRANSCRIPT_ANALYSIS_CHUNK_SIZE=20

# 全局并发上限：同时最多处理的 session 数
TRANSCRIPT_ANALYSIS_CONCURRENCY=3

# 是否只处理 isFinal=true 的事件（兼容未来回写；1/true 启用，0/false 关闭）
TRANSCRIPT_ANALYSIS_REQUIRE_FINAL=0

# 可选：语义分析使用的 GLM 配置
GLM_TRANSCRIPT_ANALYSIS_MODEL=glm-4.6v-flash
GLM_TRANSCRIPT_ANALYSIS_MAX_TOKENS=2000 # 输出 token 上限（不等于上下文窗口）
GLM_TRANSCRIPT_ANALYSIS_JSON_MODE=1

# 后端到 ASR 服务的 WebSocket Endpoint
TRANSCRIPT_ENDPOINT=wss://openspeech.bytedance.com/api/v3/sauc/bigmodel_async

# 兼容字段：ConfigurationService 读取 transcript.apiKey（如你实现基于 API Key 的转写服务）
TRANSCRIPT_API_KEY=

# 豆包 ASR 鉴权配置（backend/src/modules/transcript/doubao.client.ts 必需）
TRANSCRIPT_APP_KEY=your_transcript_app_key
TRANSCRIPT_ACCESS_KEY=your_transcript_access_key

# 可选：资源 ID（按你开通的规格选择；不填会使用默认值）
# - Java demo（sauc/bigmodel_async）：volc.bigasr.sauc.duration
# - 其他规格（以你实际开通为准）：volc.seedasr.sauc.duration / volc.seedasr.sauc.concurrent
TRANSCRIPT_RESOURCE_ID=volc.bigasr.sauc.duration

# 可选：等待 ASR 响应的超时时间（毫秒），默认 5000
TRANSCRIPT_RESPONSE_TIMEOUT_MS=5000

# 可选：Config 是否使用 gzip（默认 true；若服务端不接受可设为 false）
TRANSCRIPT_CONFIG_GZIP=true

# 可选：音频包是否使用 gzip（默认 true；对齐 Java demo；若服务端不接受可设为 false）
TRANSCRIPT_AUDIO_GZIP=true
